{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edaa7693-0605-4719-ada0-8b44be7650c8",
   "metadata": {},
   "source": [
    "# Esercitazione 3\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "2025/03/27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da5d83-2dd6-422d-b2d1-048c35421d0f",
   "metadata": {},
   "source": [
    "## Struttura della soluzione generale\n",
    "\n",
    "1. Viene creata una funzione `nested_cv` per automatizzare il processo di inner e outer cross-validation.\n",
    "2. Si chiama la funzione del modello in questione, specificando la lista dei parametri in modo da utilizzare poi il metodo `nested_cv`.\n",
    "3. Dato che i modelli riportano quasi le stesse metriche di valutazione, viene misurato anche il tempo di esecuzione dei processi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad35f120-4217-4eca-8ec7-68d12cda9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee43097-cb8a-4206-874f-3b0534c21d36",
   "metadata": {},
   "source": [
    "#### Implementazione di `nested_cv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a1b69-748a-4d05-b867-8f097f2ca6ee",
   "metadata": {},
   "source": [
    "Il metodo `nested_cv` ottimizza gli iperparametri mediante la `GridSearchCV` nella parte interna e valuta il modello sulla parte esterna del dataset.\n",
    "\n",
    "Per ogni iterazione, calcola le metriche di valutazione richieste: $R^2$, $MAE$ (Mean Absolute Error) e $RMSE$ (Root Mean Squared Error) restituendo la *media* e la *deviazione standard* di ciascuna metrica. \n",
    "\n",
    "Parametri della funzione `nested_cv`:\n",
    "- `model`: il modello di regressione in input;\n",
    "- `param_grid`: il dizionario degli iperparametri per `GridSearchCV`;\n",
    "- `X, y`: feature e variabile target;\n",
    "- `outer_splits`: il numero di fold per la Cross-Validation Esterna (`default = 5`);\n",
    "- `inner_splits`: il numero di fold per la Cross-Validation Interna (`default = 5`);\n",
    "- `scoring`: lista delle metriche per la valutazione;\n",
    "- `random_state`: seed per la riproducibilità dell'esperimento.\n",
    "\n",
    "Output del metodo:\n",
    "- Il dizionario con la media e la deviazione standard di ciascuna misura di valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6abbf84-b118-45d2-8116-85daddfc6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error\n",
    "\n",
    "def nested_cv(model, param_grid, X, y, outer_splits = 5,\n",
    "              inner_splits = 5, scoring = ['r2'], random_state = 42):\n",
    "\n",
    "    # Outer Cross Validation\n",
    "    outer_cv = KFold(n_splits = outer_splits, shuffle = True, random_state = random_state)\n",
    "    \n",
    "    score_results = {metric: [] for metric in scoring}\n",
    "\n",
    "    for train_idx, test_idx in outer_cv.split(X):\n",
    "        \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Inner Cross Validation\n",
    "        inner_cv = KFold(n_splits = inner_splits, shuffle = True, random_state = random_state)\n",
    "        grid_search = GridSearchCV(model, param_grid, cv = inner_cv,\n",
    "                                   n_jobs = -1, scoring = scoring[0])\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        if 'r2' in scoring:\n",
    "            score_results['r2'].append(r2_score(y_test, y_pred))\n",
    "            \n",
    "        if 'mae' in scoring:\n",
    "            score_results['mae'].append(mean_absolute_error(y_test, y_pred))\n",
    "            \n",
    "        if 'rmse' in scoring:\n",
    "            score_results['rmse'].append(root_mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for metric, scores in score_results.items():\n",
    "        result[f\"Nested CV {metric.upper()}\"] = f\"{np.mean(scores):.4f} ± {np.std(scores):.4f}\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4b0df-ddb5-4ad4-b00a-552ac1cb0c74",
   "metadata": {},
   "source": [
    "Nested Cross-Validation:\n",
    "\n",
    "> https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138fc46-dc22-42b8-bee9-c441087cf791",
   "metadata": {},
   "source": [
    "#### Scaling del dataset\n",
    "\n",
    "Il dataset scelto per l'esercitazione è `california_hounsing`, utile per i modelli di regressione. Si è scelto di utilizzare uno `StandardScaler` per normalizzare i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e74533-72eb-4ebd-8cc9-cc4c0d64b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X) # Normalizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961e0c7-8641-42cd-a1ec-0cf3e1d0adeb",
   "metadata": {},
   "source": [
    "## Esercizio 1\n",
    "\n",
    "Confronto di più regressori della stessa categoria (quelli base, con regolarizzazione, robusti) su un dataset concordato con Cross Validation (k-Fold Validation come esterna, GridSearch come interna) e fine tuning degli iperparametri. \n",
    "\n",
    "Le metriche da prendere in considerazione sono $R^2$ e $RMSE$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae87309-47a3-4d40-b4c4-06438a9bfb54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Scelta della categoria di Regressori**\n",
    "\n",
    "I regressori che utilizzano la **regolarizzazione** scelti:\n",
    "* Ridge\n",
    "* Lasso\n",
    "* ElasticNet\n",
    "* SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ae3ae-5bff-4011-96eb-f6a64ef7fc74",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "La formula della Ridge Regression è la seguente:\n",
    "$$\n",
    "J(\\mathbf{w})= \\text{MSE}(\\mathbf{w})+\\alpha\\dfrac{1}{2}\\sum_i w_i^2\n",
    "$$\n",
    "\n",
    "La regolarizzazione $\\mathcal{l}_2$ è la sfera rappresentata nell'immagine sotto.\n",
    "\n",
    "<center><img src = 'https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch04/images/04_05.png' width = 500></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0043e24d-2fc8-4d02-ac4f-8e5fc8543c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Results: \n",
      " {'Nested CV R2': '0.6014 ± 0.0170', 'Nested CV RMSE': '0.7282 ± 0.0150'}\n",
      "Training Ridge model in 39.131s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "ridge_params = {\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'fit_intercept': [True, False],\n",
    "    'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "ridge_results = nested_cv(ridge_model, ridge_params, X_std, y, \n",
    "                          outer_splits = 5, inner_splits = 5, \n",
    "                          scoring = ['r2', 'rmse'])\n",
    "\n",
    "print(f'Ridge Regression Results: \\n {ridge_results}')\n",
    "print(f'Training Ridge model in {(time() - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4abd5e-8741-47c4-81ac-f6449bfb8ce7",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "\n",
    "La formula della Ridge Regression è la seguente:\n",
    "$$\n",
    "J(\\mathbf{w}) = \\text{MSE}(\\mathbf{w}) + \\alpha  \\sum_i |w|_i =  \\dfrac{1}{2N} \\|y - \\mathbf{Xw}\\|^2_2 + \\alpha  \\|\\mathbf{w}\\|_1\n",
    "$$\n",
    "\n",
    "La regolarizzazione $\\mathcal{l}_1$ è il quadrato ruotato rappresentato in figura.\n",
    "\n",
    "<center><img src = 'https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch04/images/04_06.png' width = 500></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c784ed4-e33e-4322-bcfe-f2ac9b813f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Results: \n",
      " {'Nested CV R2': '0.6023 ± 0.0176', 'Nested CV RMSE': '0.7274 ± 0.0155'}\n",
      "Trained Lasso model in 1.978s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "lasso_model = Lasso() # max_iter = 1000\n",
    "\n",
    "lasso_params = {\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'fit_intercept': [True, False]}\n",
    "\n",
    "lasso_results = nested_cv(lasso_model, lasso_params, X_std, y, \n",
    "                          outer_splits=5, inner_splits=5, \n",
    "                          scoring=['r2', 'rmse'])\n",
    "\n",
    "print(f'Lasso Regression Results: \\n {lasso_results}')\n",
    "print(f'Trained Lasso model in {(time() - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8690370-bf0a-43bb-81de-61ffcd17df30",
   "metadata": {},
   "source": [
    "### ElasticNet\n",
    "\n",
    "La ElasticNet unisce le regolarizzazioni della Ridge Regression e della Lasso.\n",
    "\n",
    "$$\\min_\\mathbf{w} \\frac{1}{N}\\|\\mathbf{Xw}-y\\|^2_2 + \\alpha\\rho\\|\\mathbf{w}\\|_1 + \\frac{1}{2}\\alpha(1-\\rho)\\|\\mathbf{w}\\|_2$$\n",
    "\n",
    "Il parametro $\\alpha$ è della regolarizzazione $\\mathcal{l}_2$, mentre $\\rho$ è la penalizzazione della $\\mathcal{l}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276d7b7a-a43f-4565-91d7-d1a5b00f120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Regression Results: \n",
      " {'Nested CV R2': '0.6022 ± 0.0177', 'Nested CV RMSE': '0.7274 ± 0.0156'}\n",
      "Trained ElasticNet model in 1.930s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "en_model = ElasticNet()\n",
    "\n",
    "en_params = {\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'fit_intercept': [True, False]}\n",
    "\n",
    "en_results = nested_cv(en_model, en_params, X_std, y, \n",
    "                       outer_splits = 5, inner_splits = 5, \n",
    "                       scoring = ['r2', 'rmse'], random_state = 42)\n",
    "\n",
    "print(f'ElasticNet Regression Results: \\n {en_results}')\n",
    "print(f'Trained ElasticNet model in {(time() - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25305c8-6984-4ccc-b0c0-af4548e49d20",
   "metadata": {},
   "source": [
    "### SGD Regression\n",
    "\n",
    "La regressione mediante discesa del gradiente stocastica è un metodo iterativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06221b11-1202-41ae-8d22-1c507dff2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Regression Results: \n",
      " {'Nested CV R2': '0.5687 ± 0.0187', 'Nested CV RMSE': '0.7575 ± 0.0168'}\n",
      "Trained SGD model in 13.462s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "SGD_model = SGDRegressor()\n",
    "\n",
    "sgd_params = {\n",
    "    'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "sgd_results = nested_cv(SGD_model, sgd_params, X_std, y, \n",
    "                        outer_splits = 5, inner_splits = 5, \n",
    "                        scoring = ['r2', 'rmse'], random_state = 42)\n",
    "\n",
    "print(f'SGD Regression Results: \\n {sgd_results}')\n",
    "print(f'Trained SGD model in {(time() - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a1200-e1ab-4582-b8ed-5745e0e5ae2f",
   "metadata": {},
   "source": [
    "## Esercizio 2\n",
    "\n",
    "Confronto di più regressori di categorie diverse su un dataset concordato con Cross Validation e fine tuning degli iperparametri.\n",
    "\n",
    "Le metriche da prendere in considerazione sono: $R^2$ e $MAE$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bb727-d275-4cf9-b733-cfd9679620ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Scelta dei Regressori**\n",
    "\n",
    "I regressori scelti per il confronto sono i seguenti:\n",
    "* Linear\n",
    "* RANSAC\n",
    "* Bayesian Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b6544-d680-435c-a5ea-0af8faad667e",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c50d82-1622-4a44-8bbb-4c9a6e3a548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results: \n",
      " {'Nested CV R2': '0.6014 ± 0.0170', 'Nested CV MAE': '0.5317 ± 0.0084'}\n",
      "Trained linear model in 1.013s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_param = {\n",
    "    'fit_intercept': [True, False] \n",
    "}\n",
    "\n",
    "linear_results = nested_cv(linear_model, linear_param, X_std, y, \n",
    "                           outer_splits = 5, inner_splits = 5, \n",
    "                           scoring = ['r2', 'mae'])\n",
    "\n",
    "print(f'Linear Regression Results: \\n {linear_results}')\n",
    "print(f'Trained linear model in {(time() - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414bad6-5cb9-490e-a7d9-50615aa66a0f",
   "metadata": {},
   "source": [
    "### RANSAC Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4fe38c-befb-40a2-8f96-75e7b3dc66db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSAC Regression Results: \n",
      " {'Nested CV R2': '0.6023 ± 0.0166', 'Nested CV MAE': '0.5307 ± 0.0081'}\n",
      "Trained RANSAC model in 19.615s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "ransac_model = RANSACRegressor()\n",
    "\n",
    "ransac_params = {\n",
    "    'min_samples': [0.5, 0.7, 0.9],  \n",
    "    'residual_threshold': [5.0, 10.0, 15.0],  \n",
    "    'loss': ['absolute_error', 'squared_error']\n",
    "}\n",
    "\n",
    "ransac_results = nested_cv(ransac_model, ransac_params, X_std, y, \n",
    "                           outer_splits = 5, inner_splits = 5, \n",
    "                           scoring = ['r2', 'mae'], random_state = 42)\n",
    "\n",
    "print(f'RANSAC Regression Results: \\n {ransac_results}')\n",
    "print(f'Trained RANSAC model in {(time() - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed42980-e6c8-4f70-978e-9635ec2f3096",
   "metadata": {},
   "source": [
    "### Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dffeeb7-a9a0-4d8a-9627-a20924b6c95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Ridge Regression Results: \n",
      " {'Nested CV R2': '0.6014 ± 0.0170', 'Nested CV MAE': '0.5317 ± 0.0084'}\n",
      "Trained Bayesian Ridge model in 11.508s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "bayesian_ridge_model = BayesianRidge()\n",
    "\n",
    "bayesian_param = {\n",
    "    'alpha_1': [1e-6, 1e-3, 1e-1, 1],\n",
    "    'alpha_2': [1e-6, 1e-3, 1e-1, 1],\n",
    "    'lambda_1': [1e-6, 1e-3, 1e-1, 1],\n",
    "    'lambda_2': [1e-6, 1e-3, 1e-1, 1]\n",
    "}\n",
    "\n",
    "bayesian_ridge_results = nested_cv(bayesian_ridge_model, bayesian_param, X_std, y, \n",
    "                                   outer_splits = 5, inner_splits = 5, scoring = ['r2', 'mae'])\n",
    "\n",
    "print(f'Bayesian Ridge Regression Results: \\n {bayesian_ridge_results}')\n",
    "print(f'Trained Bayesian Ridge model in {(time() - t0):.3f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
