{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edaa7693-0605-4719-ada0-8b44be7650c8",
   "metadata": {},
   "source": [
    "# Esercitazione 4\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "2025/03/27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da5d83-2dd6-422d-b2d1-048c35421d0f",
   "metadata": {},
   "source": [
    "## Struttura della soluzione generale\n",
    "\n",
    "1. Viene creata una funzione `nested_cv` per automatizzare il processo di inner e outer cross-validation.\n",
    "2. Si chiama la funzione del modello in questione, specificando la lista dei parametri in modo da utilizzare poi il metodo `nested_cv`.\n",
    "3. Dato che i modelli riportano quasi le stesse metriche di valutazione, viene misurato anche il tempo di esecuzione dei processi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad35f120-4217-4eca-8ec7-68d12cda9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee43097-cb8a-4206-874f-3b0534c21d36",
   "metadata": {},
   "source": [
    "#### Implementazione di `nested_cv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a1b69-748a-4d05-b867-8f097f2ca6ee",
   "metadata": {},
   "source": [
    "Il metodo `nested_cv` ottimizza gli iperparametri mediante la `GridSearchCV` nella parte interna e valuta il modello sulla parte esterna del dataset.\n",
    "\n",
    "Per ogni iterazione, calcola le metriche di valutazione richieste: $R^2$, $MAE$ (Mean Absolute Error) e $RMSE$ (Root Mean Squared Error) restituendo la *media* e la *deviazione standard* di ciascuna metrica. \n",
    "\n",
    "Parametri della funzione `nested_cv`:\n",
    "- `model`: il modello di regressione in input;\n",
    "- `param_grid`: il dizionario degli iperparametri per `GridSearchCV`;\n",
    "- `X, y`: feature e variabile target;\n",
    "- `outer_splits`: il numero di fold per la Cross-Validation Esterna (`default = 5`);\n",
    "- `inner_splits`: il numero di fold per la Cross-Validation Interna (`default = 5`);\n",
    "- `scoring`: lista delle metriche per la valutazione;\n",
    "- `random_state`: seed per la riproducibilità dell'esperimento.\n",
    "\n",
    "Output del metodo:\n",
    "- Il dizionario con la media e la deviazione standard di ciascuna misura di valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6abbf84-b118-45d2-8116-85daddfc6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def nested_cv_regression(model, param_grid, X, y, outer_splits=5,\n",
    "                         inner_splits=5, scoring=None, random_state=42, verbose=True):\n",
    "    if scoring is None:\n",
    "        scoring = ['r2']  # Default metric\n",
    "\n",
    "    outer_cv = KFold(n_splits=outer_splits, shuffle=True, random_state=random_state)\n",
    "    score_results = {metric: [] for metric in scoring}\n",
    "\n",
    "    best_param_overall = None\n",
    "    best_r2_score = -np.inf \n",
    "\n",
    "    for outer_fold, (train_idx, test_idx) in enumerate(outer_cv.split(X), 1):\n",
    "        if verbose:\n",
    "            print(f\"\\nPerforming Outer Fold {outer_fold}/{outer_splits}\")\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        inner_cv = KFold(n_splits=inner_splits, shuffle=True, random_state=random_state)\n",
    "        if verbose:\n",
    "            print(\"Performing GridSearchCV...\")\n",
    "\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=inner_cv,\n",
    "                                   n_jobs=-1, scoring=scoring[0])\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        if verbose:\n",
    "            print(f\" Best Params: {best_params}\")\n",
    "\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        if 'r2' in scoring:\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            score_results['r2'].append(r2)\n",
    "            if r2 > best_r2_score:\n",
    "                best_r2_score = r2\n",
    "                best_param_overall = best_params\n",
    "            if verbose:\n",
    "                print(f\" R²: {r2:.4f}\")\n",
    "\n",
    "        if 'mae' in scoring:\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            score_results['mae'].append(mae)\n",
    "            if verbose:\n",
    "                print(f\" MAE: {mae:.4f}\")\n",
    "\n",
    "        if 'rmse' in scoring:\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            score_results['rmse'].append(rmse)\n",
    "            if verbose:\n",
    "                print(f\" RMSE: {rmse:.4f}\")\n",
    "\n",
    "    result = {}\n",
    "    for metric, scores in score_results.items():\n",
    "        result[f\"Nested CV {metric.upper()}\"] = f\"{np.mean(scores):.4f} ± {np.std(scores):.4f}\"\n",
    "\n",
    "    result[\"Best Parameters with highest R2 score\"] = best_param_overall\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4b0df-ddb5-4ad4-b00a-552ac1cb0c74",
   "metadata": {},
   "source": [
    "Nested Cross-Validation:\n",
    "\n",
    "> https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138fc46-dc22-42b8-bee9-c441087cf791",
   "metadata": {},
   "source": [
    "#### Scaling del dataset\n",
    "\n",
    "Il dataset scelto per l'esercitazione è `california_hounsing`, utile per i modelli di regressione. Si è scelto di utilizzare uno `StandardScaler` per normalizzare i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18e74533-72eb-4ebd-8cc9-cc4c0d64b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961e0c7-8641-42cd-a1ec-0cf3e1d0adeb",
   "metadata": {},
   "source": [
    "## Esercizio 1\n",
    "\n",
    "Confronto di più regressori della stessa categoria (quelli base, con regolarizzazione, robusti) su un dataset concordato con Cross Validation (k-Fold Validation come esterna, GridSearch come interna) e fine tuning degli iperparametri. \n",
    "\n",
    "Le metriche da prendere in considerazione sono $R^2$ e $RMSE$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae87309-47a3-4d40-b4c4-06438a9bfb54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Scelta della categoria di Regressori**\n",
    "\n",
    "I regressori che utilizzano la **regolarizzazione** scelti:\n",
    "* Ridge\n",
    "* Lasso\n",
    "* ElasticNet\n",
    "* SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ae3ae-5bff-4011-96eb-f6a64ef7fc74",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "La formula della Ridge Regression è la seguente:\n",
    "$$\n",
    "J(\\mathbf{w})= \\text{MSE}(\\mathbf{w})+\\alpha\\dfrac{1}{2}\\sum_i w_i^2\n",
    "$$\n",
    "\n",
    "La regolarizzazione $\\mathcal{l}_2$ è la sfera rappresentata nell'immagine sotto.\n",
    "\n",
    "<center><img src = 'https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch04/images/04_05.png' width = 500></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3a5923e-5636-4bcc-be36-e8b991e8f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0043e24d-2fc8-4d02-ac4f-8e5fc8543c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Outer Fold 1/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      " R²: 0.5757\n",
      " RMSE: 0.7456\n",
      "\n",
      "Performing Outer Fold 2/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 1, 'fit_intercept': True, 'solver': 'svd'}\n",
      " R²: 0.6137\n",
      " RMSE: 0.7264\n",
      "\n",
      "Performing Outer Fold 3/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 1, 'fit_intercept': True, 'solver': 'sparse_cg'}\n",
      " R²: 0.6086\n",
      " RMSE: 0.7137\n",
      "\n",
      "Performing Outer Fold 4/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}\n",
      " R²: 0.6213\n",
      " RMSE: 0.7105\n",
      "\n",
      "Performing Outer Fold 5/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 1, 'fit_intercept': True, 'solver': 'lsqr'}\n",
      " R²: 0.5875\n",
      " RMSE: 0.7451\n",
      "Ridge Regression Results: \n",
      " {'Nested CV R2': '0.6014 ± 0.0170', 'Nested CV RMSE': '0.7282 ± 0.0150', '\\nBest Parameters with highest R2 score': {'alpha': 1, 'fit_intercept': True, 'solver': 'saga'}}\n",
      "Training Ridge model in 52.285s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "ridge_model = Ridge()\n",
    "\n",
    "ridge_params = {\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'fit_intercept': [True, False],\n",
    "    'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "ridge_results = nested_cv_regression(ridge_model, ridge_params, X_std, y, \n",
    "                          outer_splits = 5, inner_splits = 5, \n",
    "                          scoring = ['r2', 'rmse'])\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f'Ridge Regression Results: \\n {ridge_results}')\n",
    "print(f'Training Ridge model in {(t1 - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4abd5e-8741-47c4-81ac-f6449bfb8ce7",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "\n",
    "La formula della Ridge Regression è la seguente:\n",
    "$$\n",
    "J(\\mathbf{w}) = \\text{MSE}(\\mathbf{w}) + \\alpha  \\sum_i |w|_i =  \\dfrac{1}{2N} \\|y - \\mathbf{Xw}\\|^2_2 + \\alpha  \\|\\mathbf{w}\\|_1\n",
    "$$\n",
    "\n",
    "La regolarizzazione $\\mathcal{l}_1$ è il quadrato ruotato rappresentato in figura.\n",
    "\n",
    "<center><img src = 'https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch04/images/04_06.png' width = 500></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c784ed4-e33e-4322-bcfe-f2ac9b813f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Outer Fold 1/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.5769\n",
      " RMSE: 0.7446\n",
      "\n",
      "Performing Outer Fold 2/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.6136\n",
      " RMSE: 0.7266\n",
      "\n",
      "Performing Outer Fold 3/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.6080\n",
      " RMSE: 0.7141\n",
      "\n",
      "Performing Outer Fold 4/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.01, 'fit_intercept': True}\n",
      " R²: 0.6253\n",
      " RMSE: 0.7068\n",
      "\n",
      "Performing Outer Fold 5/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.5878\n",
      " RMSE: 0.7448\n",
      "Lasso Regression Results: \n",
      " {'Nested CV R2': '0.6023 ± 0.0176', 'Nested CV RMSE': '0.7274 ± 0.0155', '\\nBest Parameters with highest R2 score': {'alpha': 0.01, 'fit_intercept': True}}\n",
      "Trained Lasso model in 2.097s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "lasso_model = Lasso() # max_iter = 1000\n",
    "\n",
    "lasso_params = {\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'fit_intercept': [True, False]}\n",
    "\n",
    "lasso_results = nested_cv_regression(lasso_model, lasso_params, X_std, y, \n",
    "                          outer_splits=5, inner_splits=5, \n",
    "                          scoring=['r2', 'rmse'])\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f'Lasso Regression Results: \\n {lasso_results}')\n",
    "print(f'Trained Lasso model in {(t1 - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8690370-bf0a-43bb-81de-61ffcd17df30",
   "metadata": {},
   "source": [
    "### ElasticNet\n",
    "\n",
    "La ElasticNet unisce le regolarizzazioni della Ridge Regression e della Lasso.\n",
    "\n",
    "$$\\min_\\mathbf{w} \\frac{1}{N}\\|\\mathbf{Xw}-y\\|^2_2 + \\alpha\\rho\\|\\mathbf{w}\\|_1 + \\frac{1}{2}\\alpha(1-\\rho)\\|\\mathbf{w}\\|_2$$\n",
    "\n",
    "Il parametro $\\alpha$ è della regolarizzazione $\\mathcal{l}_2$, mentre $\\rho$ è la penalizzazione della $\\mathcal{l}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "276d7b7a-a43f-4565-91d7-d1a5b00f120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Outer Fold 1/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.5766\n",
      " RMSE: 0.7449\n",
      "\n",
      "Performing Outer Fold 2/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.6136\n",
      " RMSE: 0.7265\n",
      "\n",
      "Performing Outer Fold 3/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.6082\n",
      " RMSE: 0.7140\n",
      "\n",
      "Performing Outer Fold 4/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.01, 'fit_intercept': True}\n",
      " R²: 0.6251\n",
      " RMSE: 0.7069\n",
      "\n",
      "Performing Outer Fold 5/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True}\n",
      " R²: 0.5877\n",
      " RMSE: 0.7450\n",
      "ElasticNet Regression Results: \n",
      " {'Nested CV R2': '0.6022 ± 0.0177', 'Nested CV RMSE': '0.7274 ± 0.0156', 'Best Parameters with highest R2 score': {'alpha': 0.01, 'fit_intercept': True}}\n",
      "Trained ElasticNet model in 2.118s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "en_model = ElasticNet()\n",
    "\n",
    "en_params = {\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'fit_intercept': [True, False]}\n",
    "\n",
    "en_results = nested_cv_regression(en_model, en_params, X_std, y, \n",
    "                       outer_splits = 5, inner_splits = 5, \n",
    "                       scoring = ['r2', 'rmse'], random_state = 42)\n",
    "t1 = time.time()\n",
    "\n",
    "print(f'ElasticNet Regression Results: \\n {en_results}')\n",
    "print(f'Trained ElasticNet model in {(t1 - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25305c8-6984-4ccc-b0c0-af4548e49d20",
   "metadata": {},
   "source": [
    "### SGD Regression\n",
    "\n",
    "La regressione mediante discesa del gradiente stocastica è un metodo iterativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06221b11-1202-41ae-8d22-1c507dff2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Outer Fold 1/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.1, 'fit_intercept': True, 'loss': 'squared_error', 'penalty': 'elasticnet'}\n",
      " R²: 0.5440\n",
      " RMSE: 0.7730\n",
      "\n",
      "Performing Outer Fold 2/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.01, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'penalty': 'l1'}\n",
      " R²: 0.5878\n",
      " RMSE: 0.7504\n",
      "\n",
      "Performing Outer Fold 3/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.01, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'penalty': 'l1'}\n",
      " R²: 0.5870\n",
      " RMSE: 0.7330\n",
      "\n",
      "Performing Outer Fold 4/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.001, 'fit_intercept': True, 'loss': 'squared_error', 'penalty': None}\n",
      " R²: 0.6202\n",
      " RMSE: 0.7115\n",
      "\n",
      "Performing Outer Fold 5/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha': 0.0001, 'fit_intercept': True, 'loss': 'huber', 'penalty': None}\n",
      " R²: 0.5488\n",
      " RMSE: 0.7793\n",
      "SGD Regression Results: \n",
      " {'Nested CV R2': '0.5775 ± 0.0282', 'Nested CV RMSE': '0.7495 ± 0.0251', 'Best Parameters with highest R2 score': {'alpha': 0.001, 'fit_intercept': True, 'loss': 'squared_error', 'penalty': None}}\n",
      "Trained SGD model in 15.279s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "SGD_model = SGDRegressor()\n",
    "\n",
    "sgd_params = {\n",
    "    'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'alpha': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "sgd_results = nested_cv_regression(SGD_model, sgd_params, X_std, y, \n",
    "                        outer_splits = 5, inner_splits = 5, \n",
    "                        scoring = ['r2', 'rmse'], random_state = 42)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f'SGD Regression Results: \\n {sgd_results}')\n",
    "print(f'Trained SGD model in {(t1 - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a1200-e1ab-4582-b8ed-5745e0e5ae2f",
   "metadata": {},
   "source": [
    "## Esercizio 2\n",
    "\n",
    "Confronto di più regressori di categorie diverse su un dataset concordato con Cross Validation e fine tuning degli iperparametri.\n",
    "\n",
    "Le metriche da prendere in considerazione sono: $R^2$ e $MAE$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bb727-d275-4cf9-b733-cfd9679620ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Scelta dei Regressori**\n",
    "\n",
    "I regressori scelti per il confronto sono i seguenti:\n",
    "* Linear\n",
    "* RANSAC\n",
    "* Bayesian Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b6544-d680-435c-a5ea-0af8faad667e",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07c50d82-1622-4a44-8bbb-4c9a6e3a548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Outer Fold 1/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'fit_intercept': True}\n",
      " R²: 0.5758\n",
      " MAE: 0.5332\n",
      "\n",
      "Performing Outer Fold 2/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'fit_intercept': True}\n",
      " R²: 0.6137\n",
      " MAE: 0.5367\n",
      "\n",
      "Performing Outer Fold 3/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'fit_intercept': True}\n",
      " R²: 0.6086\n",
      " MAE: 0.5292\n",
      "\n",
      "Performing Outer Fold 4/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'fit_intercept': True}\n",
      " R²: 0.6213\n",
      " MAE: 0.5171\n",
      "\n",
      "Performing Outer Fold 5/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'fit_intercept': True}\n",
      " R²: 0.5875\n",
      " MAE: 0.5422\n",
      "Linear Regression Results: \n",
      " {'Nested CV R2': '0.6014 ± 0.0170', 'Nested CV MAE': '0.5317 ± 0.0084', 'Best Parameters per fold': [{'fit_intercept': True}, {'fit_intercept': True}, {'fit_intercept': True}, {'fit_intercept': True}, {'fit_intercept': True}]}\n",
      "Trained linear model in 0.855s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_param = {\n",
    "    'fit_intercept': [True, False] \n",
    "}\n",
    "\n",
    "linear_results = nested_cv(linear_model, linear_param, X_std, y, \n",
    "                           outer_splits = 5, inner_splits = 5, \n",
    "                           scoring = ['r2', 'mae'])\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f'Linear Regression Results: \\n {linear_results}')\n",
    "print(f'Trained linear model in {(t1 - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414bad6-5cb9-490e-a7d9-50615aa66a0f",
   "metadata": {},
   "source": [
    "### RANSAC Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a4fe38c-befb-40a2-8f96-75e7b3dc66db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Outer Fold 1/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'loss': 'absolute_error', 'min_samples': 0.5, 'residual_threshold': 5.0}\n",
      " R²: 0.5754\n",
      " MAE: 0.5332\n",
      "\n",
      "Performing Outer Fold 2/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'loss': 'absolute_error', 'min_samples': 0.7, 'residual_threshold': 5.0}\n",
      " R²: 0.6132\n",
      " MAE: 0.5353\n",
      "\n",
      "Performing Outer Fold 3/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'loss': 'absolute_error', 'min_samples': 0.9, 'residual_threshold': 5.0}\n",
      " R²: 0.6104\n",
      " MAE: 0.5271\n",
      "\n",
      "Performing Outer Fold 4/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'loss': 'absolute_error', 'min_samples': 0.5, 'residual_threshold': 10.0}\n",
      " R²: 0.6213\n",
      " MAE: 0.5171\n",
      "\n",
      "Performing Outer Fold 5/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'loss': 'squared_error', 'min_samples': 0.7, 'residual_threshold': 15.0}\n",
      " R²: 0.5911\n",
      " MAE: 0.5404\n",
      "RANSAC Regression Results: \n",
      " {'Nested CV R2': '0.6023 ± 0.0167', 'Nested CV MAE': '0.5306 ± 0.0080', 'Best Parameters with highest R2 score': {'loss': 'absolute_error', 'min_samples': 0.5, 'residual_threshold': 10.0}}\n",
      "Trained RANSAC model in 27.072s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "ransac_model = RANSACRegressor()\n",
    "\n",
    "ransac_params = {\n",
    "    'min_samples': [0.5, 0.7, 0.9],  \n",
    "    'residual_threshold': [5.0, 10.0, 15.0],  \n",
    "    'loss': ['absolute_error', 'squared_error']\n",
    "}\n",
    "\n",
    "ransac_results = nested_cv_regression(ransac_model, ransac_params, X_std, y, \n",
    "                           outer_splits = 5, inner_splits = 5, \n",
    "                           scoring = ['r2', 'mae'], random_state = 42)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f'RANSAC Regression Results: \\n {ransac_results}')\n",
    "print(f'Trained RANSAC model in {(t1 - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed42980-e6c8-4f70-978e-9635ec2f3096",
   "metadata": {},
   "source": [
    "### Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dffeeb7-a9a0-4d8a-9627-a20924b6c95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Outer Fold 1/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha_1': 1e-06, 'alpha_2': 1, 'lambda_1': 1, 'lambda_2': 1e-06}\n",
      " R²: 0.5759\n",
      " MAE: 0.5332\n",
      "\n",
      "Performing Outer Fold 2/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha_1': 1e-06, 'alpha_2': 1, 'lambda_1': 1, 'lambda_2': 1e-06}\n",
      " R²: 0.6137\n",
      " MAE: 0.5367\n",
      "\n",
      "Performing Outer Fold 3/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha_1': 1e-06, 'alpha_2': 1, 'lambda_1': 1, 'lambda_2': 1e-06}\n",
      " R²: 0.6085\n",
      " MAE: 0.5292\n",
      "\n",
      "Performing Outer Fold 4/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha_1': 1e-06, 'alpha_2': 1, 'lambda_1': 1, 'lambda_2': 1e-06}\n",
      " R²: 0.6213\n",
      " MAE: 0.5171\n",
      "\n",
      "Performing Outer Fold 5/5\n",
      "Performing GridSearchCV...\n",
      " Best Params: {'alpha_1': 1e-06, 'alpha_2': 1, 'lambda_1': 1, 'lambda_2': 1e-06}\n",
      " R²: 0.5875\n",
      " MAE: 0.5422\n",
      "Bayesian Ridge Regression Results: \n",
      " {'Nested CV R2': '0.6014 ± 0.0170', 'Nested CV MAE': '0.5317 ± 0.0084', 'Best Parameters with highest R2 score': {'alpha_1': 1e-06, 'alpha_2': 1, 'lambda_1': 1, 'lambda_2': 1e-06}}\n",
      "Trained Bayesian Ridge model in 14.283s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "bayesian_ridge_model = BayesianRidge()\n",
    "\n",
    "bayesian_param = {\n",
    "    'alpha_1': [1e-6, 1e-3, 1e-1, 1],\n",
    "    'alpha_2': [1e-6, 1e-3, 1e-1, 1],\n",
    "    'lambda_1': [1e-6, 1e-3, 1e-1, 1],\n",
    "    'lambda_2': [1e-6, 1e-3, 1e-1, 1]\n",
    "}\n",
    "\n",
    "bayesian_ridge_results = nested_cv_regression(bayesian_ridge_model,\n",
    "                                              bayesian_param, X_std, y, \n",
    "                                              outer_splits = 5, \n",
    "                                              inner_splits = 5, \n",
    "                                              scoring = ['r2', 'mae'])\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f'Bayesian Ridge Regression Results: \\n {bayesian_ridge_results}')\n",
    "print(f'Trained Bayesian Ridge model in {(t1 - t0):.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5129ea-2ce0-466f-ae69-f05f52dff488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
